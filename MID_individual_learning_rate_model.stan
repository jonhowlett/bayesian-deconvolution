functions{

  // convolution function

  vector stan_convolve(int nPoints, vector a,  vector b) {
  
    vector [nPoints] out;

    int indices[nPoints];

    for(i in 1:nPoints){
      indices[i]=i;
    }
  
    for(i in 1:nPoints){
      out[i] = dot_product(a[1:i], b[sort_desc(indices[1:i])]);

    }
 
    return(out);

  }  

}
data {

  int<lower=1> N; // Number of participants
  int<lower=1> T; // Number of trials
  int<lower=1> TR; // Number of TR timepoints
  int C_abs[N,T];  // Incentive value (absolute value of potential outcome from incentive cue)
 
  vector[N*TR] B; //BOLD signal at each TR timepoint (concatenated into a vector)

  vector[TR] HRF; // Vector representing HRF

  int trial1[N,TR]; // This is generated by first setting the specific timepoints to be convolved with the HRF 
                  // to be the trial number associated with the event, and all other timepoints to be zero,
                  // e.g. c(1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 3 ...), and then adding 1 to every entry,
                  // e.g. c(2, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 4 ...). 
                  // The purpose is to enable translation between the trial and TR levels

  int censlength; // Total number of uncensored volumes across all participants

  int cens[censlength]; // Indices of uncensored volumes (indices are counted in terms of vector of length N*TR)

}
parameters {

  real mu_LR_raw; // group mean of raw learning rate

  real mu_beta; // group mean of individual slopes

  real<lower=0> sigma_LR_raw; // group standard deviation of raw learning rate

  real<lower=0> sigma_beta; // standard deviation for group distribution of slopes

  vector[N] LR_raw; // individual raw learning rates

  vector[N] beta_PE; // individual slopes

  vector[N] intercept; // individual intercept terms

  vector<lower=0>[N] sigma; // standard deviation for BOLD signal regression

}
transformed parameters{

  vector<lower=0, upper=1>[N] LR;

  LR = inv_logit(LR_raw); // learning rate is modeled as inverse logit transform of raw learning rate

}
model {

  real adapt; // the expected incentive value for each trial

  vector[T+1] PE; // prediction error

  vector[TR] reg_PE_vect; // translates PE from trial level to TR timepoint level

  vector[N*TR] reg_PE; // concatenates across participants

  vector[N*TR] intercept_vect; // concatenates across participants

  vector[N*TR] beta_PE_vect; // concatenates across participants

  vector[N*TR] sigma_vect; // concatenates across participants


  mu_LR_raw ~ normal(0, 20);

  sigma_LR_raw ~ normal(0, 10);

  LR_raw ~ normal(mu_LR_raw, sigma_LR_raw);

  mu_beta ~ normal(0, 10);

  sigma_beta ~ normal(0, 5);

  beta_PE ~ normal(mu_beta, sigma_beta);

  intercept ~ normal(0, 10);

  sigma ~ normal(0, 5);

  // We loop through subjects

  for(n in 1:N){

    adapt=2.0;

    PE[1]=0;

    // We loop through trials

    for (t in 1:T) {

      PE[t+1] = C_abs[n,t] - adapt;

      adapt = adapt + LR[n] * PE[t+1];

    }

    reg_PE_vect=PE[trial1[n,]]; // translates from trial level to TR timepoint level
                                // PE[1] = 0; this will be assigned to all TR timepoints
                                // which are not to be convolved with the HRF
                                // PE[t+1] is the correct PE for trial t.
                                // Because of the way trial1 is generated, this will assign the correct 
                                // PE to each timepoint.

    reg_PE[((n-1)*TR+1):(n*TR)]=stan_convolve(TR, reg_PE_vect, HRF); // convolve PE with HRF

    intercept_vect[((n-1)*TR+1):(n*TR)]=rep_vector(intercept[n],TR);

    beta_PE_vect[((n-1)*TR+1):(n*TR)]=rep_vector(beta_PE[n],TR);

    sigma_vect[((n-1)*TR+1):(n*TR)]=rep_vector(sigma[n],TR);

  }

    B[cens] ~ normal(intercept_vect[cens] + beta_PE_vect[cens] .* reg_PE[cens], sigma_vect[cens]);

}
generated quantities {

  // log likelihoods stored for model comparisons

  real log_lik[censlength];

  {

  real adapt;

  vector[T+1] PE;

  vector[TR] reg_PE_vect;

  vector[TR] reg_PE;

  int index;

  index = 1;

  for(n in 1:N){

    adapt=2.0;

    PE[1]=0;

    // We loop through trials

    for (t in 1:T) {

      PE[t+1] = C_abs[n,t] - adapt;

      adapt = adapt + LR[n] * PE[t+1];

    }

    reg_PE_vect=PE[trial1[n,]];

    reg_PE=stan_convolve(TR, reg_PE_vect, HRF);

    for(tr in 1:TR){

      if(((n-1)*TR + tr) == cens[index]){

        log_lik[index] = normal_lpdf(B[(n-1)*N + tr] | intercept[n] + beta_PE[n] * reg_PE[tr], sigma[n]);

        index = index +1;

      }

    }

  }

  }

}
